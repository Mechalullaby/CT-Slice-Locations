{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('ct_data.npz')\n",
    "X_train = data['X_train']; X_val = data['X_val']; X_test = data['X_test']\n",
    "y_train = data['y_train']; y_val = data['y_val']; y_test = data['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 384)\n",
      "(5785, 384)\n",
      "(6961, 384)\n",
      "40754\n",
      "5785\n",
      "6961\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(len(y_train))\n",
    "print(len(y_val))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11690313366502872"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.13868774539957e-15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2160085093241599"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n",
    "### a). \n",
    "Report mean with a \"standard error\" in the `y_val` (should have 5,785 lines) and the first 5,785 entries in the `y_train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b).\n",
    "Identify the features that take on the same value for every training example, and remove them in the three sets.\n",
    "\n",
    "Identify indentical columns in the training set and delete the later columns in the three sets.\n",
    "\n",
    "Report which columns of the `X_...` arrays we remove as 0-based indexs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59  69 179 189 351]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Changing the shape of an F-contiguous array by descriptor assignment is deprecated. To maintain the Fortran contiguity of a multidimensional Fortran array, use 'a.T.view(...).T' instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 76]\n",
      " [283]\n",
      " [354]\n",
      " [ 77]\n",
      " [195]\n",
      " [185]]\n"
     ]
    }
   ],
   "source": [
    "repeat = []\n",
    "duplicate = []\n",
    "\n",
    "for i in range(X_train.shape[1]): \n",
    "    chara = np.array(X_train[:,i])\n",
    "    trans = chara.tolist()\n",
    "    repeat.append(len(list(set(trans))))\n",
    "repeat = np.array(repeat)\n",
    "print(np.where(repeat == 1)[0])\n",
    "\n",
    "X_train = np.delete(X_train,np.where(repeat == 1)[0],axis=1)\n",
    "X_val = np.delete(X_val,np.where(repeat == 1)[0],axis=1)\n",
    "X_test = np.delete(X_test,np.where(repeat == 1)[0],axis=1)\n",
    "\n",
    "dt = np.dtype((np.void, X_train.dtype.itemsize * X_train.shape[0]))\n",
    "dataf = np.asfortranarray(X_train).view(dt)\n",
    "u,uind = np.unique(dataf, return_inverse=True)\n",
    "u = u.view(X_train.dtype).reshape(-1,X_train.shape[0]).T\n",
    "index = [np.where(uind==x)[0] for x in range(u.shape[0])]\n",
    "\n",
    "for i in index: \n",
    "    if len(i)>1:\n",
    "        duplicate.append(i[1:])\n",
    "duplicate = np.array(duplicate)   \n",
    "print(duplicate)\n",
    "\n",
    "for k in range(len(duplicate)):\n",
    "    X_train = np.delete(X_train, duplicate[k], axis=1)\n",
    "    X_val = np.delete(X_val, duplicate[k], axis=1)\n",
    "    X_test = np.delete(X_test, duplicate[k], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 373)\n",
      "(5785, 373)\n",
      "(6961, 373)\n",
      "40754\n",
      "5785\n",
      "6961\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(len(y_train))\n",
    "print(len(y_val))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear regression baseline [15 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct_support_code import *\n",
    "def fit_linreg(X, yy, alpha):\n",
    "    n = X.shape[0]\n",
    "    # add a column of ones to X\n",
    "    X = np.hstack([X, np.ones(n).reshape(n,1)])\n",
    "\n",
    "    k = X.shape[1]\n",
    "    # add the regulation to X\n",
    "    X_tilde = np.vstack((X,np.sqrt(alpha)*np.eye(k)))\n",
    "\n",
    "    yy = np.append(yy,[0]*k) # for the regulation\n",
    "    return np.linalg.lstsq(X_tilde,yy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:12: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "fitmodel = fit_linreg(X_train, y_train, 30)\n",
    "gradopt = fit_linreg_gradopt(X_train, y_train, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the root-mean-square errors (RMSE) on the training and validation sets for the parameters fitted using both your fit_linreg and the provided fit_linreg_gradopt. Do you get exactly the same results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_linreg(fitmodel, X, yy):\n",
    "    w = fitmodel[0] # coeficients\n",
    "    n = X.shape[0]\n",
    "    X = np.hstack([X, np.ones(n).reshape(n,1)])\n",
    "    y_fit = np.dot(X, w)\n",
    "    return np.sqrt(sum((y_fit-yy)**2)/n)\n",
    "def rmse_gradopt(fitmodel, X, yy):\n",
    "    w = fitmodel[0] # coeficients\n",
    "    b = fitmodel[1]\n",
    "    n = X.shape[0]\n",
    "    y_fit = np.dot(X, w)+b\n",
    "    return np.sqrt(sum((y_fit-yy)**2)/n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fit_linreg:\n",
      "The RMSE for training set is 0.35787512881598177\n",
      "The RMSE for validation set is 0.42360525587678854\n",
      "For fit_linreg_gradopt:\n",
      "The RMSE for training set is 0.3578603283245702\n",
      "The RMSE for validation set is 0.42376229980833413\n"
     ]
    }
   ],
   "source": [
    "print('For fit_linreg:')\n",
    "print(f'The RMSE for training set is {rmse_linreg(fitmodel, X_train, y_train)}')\n",
    "print(f'The RMSE for validation set is {rmse_linreg(fitmodel, X_val, y_val)}')\n",
    "print('For fit_linreg_gradopt:')\n",
    "print(f'The RMSE for training set is {rmse_gradopt(gradopt, X_train, y_train)}')\n",
    "print(f'The RMSE for validation set is {rmse_gradopt(gradopt, X_val, y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40754, 231)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 0:231].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:12: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4092840089130781"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_linreg(fit_linreg(X_train[:, 0:231], y_train, 30), X_train[:, 0:231], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Invented classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.20446517858414\n",
      "52.69510551860815\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "K = 20 \n",
    "mx = np.max(y_train); mn = np.min(y_train); hh = (mx-mn)/(K+1)\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "class_y_train = []\n",
    "for kk in range(K):\n",
    "    labels = y_train > thresholds[kk]\n",
    "    class_y_train.append(labels+0)\n",
    "class_y_train = np.array(class_y_train)\n",
    "    \n",
    "class_y_val = []\n",
    "for kk in range(K):\n",
    "    labels = y_val > thresholds[kk]\n",
    "    class_y_val.append(labels+0)\n",
    "class_y_val = np.array(class_y_val)\n",
    "\n",
    "from ct_support_code import *\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "\n",
    "# fit the logistic regression model: \n",
    "def fit_logreg(X, yy, alpha): \n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb\n",
    "\n",
    "# fit the 20 logistic regression model: \n",
    "w_hat_m = []\n",
    "b_hat_v = []\n",
    "for i in range(20): \n",
    "    w_hat, b_hat = fit_logreg(X=X_train, yy=class_y_train[i], alpha=30)\n",
    "    w_hat_m.append(w_hat)\n",
    "    b_hat_v.append(b_hat)\n",
    "w_hat_m = np.array(w_hat_m).T\n",
    "b_hat_v = np.array(b_hat_v)\n",
    "\n",
    "# Train\n",
    "yy = 2*(class_y_train==1) - 1\n",
    "aa = yy.T * (np.dot(X_train, w_hat_m) + b_hat_v)\n",
    "# transformation of X_train matrix\n",
    "Tram_X_train = 1/(1 + np.exp(-aa))\n",
    "\n",
    "# Validation\n",
    "yy_val = 2*(class_y_val==1) - 1\n",
    "aa_val = yy_val.T * (np.dot(X_val, w_hat_m) + b_hat_v)\n",
    "# transformation of X_val matrix\n",
    "Val_X_train = 1/(1 + np.exp(-aa_val))\n",
    "\n",
    "# fit the linear model using transforming X matrix\n",
    "w_train, b_train = fit_linreg_gradopt(X=Tram_X_train, yy=y_train, alpha=30)\n",
    "w_val, b_val = fit_linreg_gradopt(X=Val_X_train, yy=y_val, alpha=30)\n",
    "\n",
    "# Calculating the RMSE\n",
    "def RMSE(para, X, yy):\n",
    "    ww = para[0] # coeficients\n",
    "    bb = para[1]\n",
    "    y_fit = np.dot(X, ww)+bb\n",
    "    return np.sqrt(sum((y_fit-yy)**2)/n)\n",
    "\n",
    "RMSE_T = RMSE(para = fit_linreg_gradopt(X=Tram_X_train, yy=y_train, alpha=30), X = Tram_X_train, yy = y_train)\n",
    "RMSE_V = RMSE(para = fit_linreg_gradopt(X=Val_X_train, yy=y_val, alpha=30), X = Val_X_train, yy = y_val)\n",
    "\n",
    "print(RMSE_T)\n",
    "print(RMSE_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Small neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.631114822794057\n",
      "28.603358884797796\n"
     ]
    }
   ],
   "source": [
    "from ct_support_code import *\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "\n",
    "# a) Using random initialization of the parameters\n",
    "def fit_nn_random(X, yy, alpha): \n",
    "    args = (X, yy, alpha)\n",
    "    V = 0.1*np.random.randn(K, X.shape[1])/np.sqrt(X.shape[1])\n",
    "    bk = 0.1*np.random.randn(K)/np.sqrt(K)\n",
    "    ww = 0.1*np.random.randn(K)/np.sqrt(K)  \n",
    "    bb = 0.1*np.random.randn(1)\n",
    "    init = (ww, bb, V, bk)\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk\n",
    "\n",
    "# b) Using parameters initialized using the fits made in Q3\n",
    "def fit_nn_logi(X, yy, alpha): \n",
    "    args = (X, yy, alpha)\n",
    "    V = w_hat_m.T\n",
    "    bk = b_hat_v\n",
    "    ww = w_train  \n",
    "    bb = b_train\n",
    "    init = (ww, bb, V, bk)\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk\n",
    "\n",
    "# Prediction: \n",
    "np.random.seed(0)\n",
    "ww, bb, V, bk = fit_nn_random(X = X_train, yy = y_train, alpha = 30)\n",
    "para = (ww, bb, V, bk)\n",
    "RMSE_random = np.sqrt(sum((nn_cost(para, X=X_train, yy=None, alpha=None) - y_train)**2))\n",
    "www, bbb, VV, bkk = fit_nn_logi(X = X_train, yy = y_train, alpha = 30)\n",
    "para_logi = (www,bbb,VV,bkk)\n",
    "RMSE_logi = np.sqrt(sum((nn_cost(para_logi, X=X_train, yy=None, alpha=None) - y_train)**2))\n",
    "\n",
    "print(RMSE_random)\n",
    "print(RMSE_logi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bayesian optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ct_support_code import *\n",
    "import scipy.stats\n",
    "\n",
    "# trains the neural network for an alpha, returns the validation RMSE\n",
    "def train_nn_reg(X, yy, X_val, y_val, alpha):\n",
    "    ww, bb, V, bk = fit_nn_random(X, yy, alpha)\n",
    "    para = (ww, bb, V, bk)\n",
    "    y_fit = nn_cost(para, X=X_val)\n",
    "    return np.sqrt(sum((y_fit-y_val)**2)/len(y_fit))\n",
    "\n",
    "# function for generating y\n",
    "base = train_nn_reg(X_train, y_train, X_val, y_val, 30)\n",
    "def LRMSE(X, yy, X_val, y_val, alpha):\n",
    "    return np.log(base/train_nn_reg(X, yy, X_val, y_val, alpha))\n",
    "\n",
    "# select next alpha according to PoI\n",
    "def next_alpha(mu_star, cov_star, y_alpha):\n",
    "    PoI = scipy.stats.norm.pdf((mu_star - max(y_alpha))/np.sqrt(np.diag(cov_star)))\n",
    "    max_PoI = max(PoI)\n",
    "    max_alpha = X_star[np.where(PoI==max_PoI)[0][0]]\n",
    "    return max_PoI, max_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 50, 0.02)\n",
    "# Pick three alphas from this set for as training locations, \n",
    "ind = len(alphas)/4\n",
    "X_alpha = alphas.take([ind-1,ind*2-1,ind*3-1])\n",
    "# remaining locations as values for the acquisition function\n",
    "X_star = np.setdiff1d(alphas, X_alpha)\n",
    "\n",
    "# generate y for the picked alpha\n",
    "y_alpha = np.zeros(len(X_alpha)) \n",
    "for i in range(len(X_alpha)):\n",
    "    y_alpha[i] = LRMSE(X_train, y_train, X_val, y_val, X_alpha[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum probability of improvement is 0.3762439131308956, with alpha = 13.86, for iteration 1\n",
      "The maximum probability of improvement is 0.3622776781757357, with alpha = 9.08, for iteration 2\n",
      "The maximum probability of improvement is 0.34566890861340177, with alpha = 9.1, for iteration 3\n",
      "The maximum probability of improvement is 0.35452121459600816, with alpha = 9.06, for iteration 4\n",
      "The maximum probability of improvement is 0.3173822033001063, with alpha = 4.96, for iteration 5\n"
     ]
    }
   ],
   "source": [
    "# retrain, do five iterations\n",
    "iteration = 0\n",
    "while iteration < 5:\n",
    "    # calculate the posterior Gaussian Process\n",
    "    mu_star, cov_star = gp_post_par(X_star, X_alpha, y_alpha)\n",
    "    # select next alpha according to PoI\n",
    "    max_PoI, alpha_new = next_alpha(mu_star, cov_star, y_alpha)\n",
    "    iteration += 1\n",
    "    print(f'The maximum probability of improvement is {max_PoI}, with alpha = {alpha_new}, for iteration {iteration}')\n",
    "    X_alpha = np.append(X_alpha, alpha_new)\n",
    "    X_star = np.setdiff1d(alphas, X_alpha)\n",
    "    y_alpha = np.append(y_alpha, LRMSE(X_train, y_train, X_val, y_val, alpha_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha is 12.48, with its validation RMSE is 0.2582302787839227 and test RMSE is 0.2892353771241661\n"
     ]
    }
   ],
   "source": [
    "# report the best alpha\n",
    "best_alpha = X_alpha[np.where(y_alpha==max(y_alpha))[0][0]]\n",
    "\n",
    "val_RMSE = train_nn_reg(X_train, y_train, X_val, y_val, best_alpha)\n",
    "test_RMSE = train_nn_reg(X_train, y_train, X_test, y_test, best_alpha)\n",
    "\n",
    "print(f'The best alpha is {best_alpha}, with its validation RMSE is {val_RMSE} and test RMSE is {test_RMSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8], dtype=int64),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_alpha==max(y_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.48, 24.98, 37.48, 13.86,  9.08,  9.1 ,  9.06,  4.96,  0.52])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.798679726995577"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is improved with smaller validation and test RMSEs. The observation noise can come from the random selection of initial parameters in the neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. What next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# 初始化模型\n",
    "LGBR = lgb.LGBMRegressor() # 基模型\n",
    "# 训练/fit拟合\n",
    "LGBR.fit(X_train, y_train)\n",
    "# 预测\n",
    "y_pred = LGBR.predict(X_test)\n",
    "# 评估\n",
    "rmse = np.sqrt(sum((y_pred-y_test)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.153938563854627"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5785, 373)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "       -0.25    , -0.25    , -0.25    , -0.25    ,  0.      ,  0.      ,\n",
       "        0.      ,  0.8     ,  0.      ,  0.      ,  0.      , -0.25    ,\n",
       "       -0.25    , -0.25    ,  0.      ,  0.      ,  0.      ,  0.956533,\n",
       "        0.8521  ,  0.      ,  0.      ,  0.      ,  0.      , -0.25    ,\n",
       "        0.      ,  0.      ,  0.      ,  0.932476,  0.960794,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.791258,  0.979383,  0.8725  ,  0.      ,  0.      ,\n",
       "        0.      , -0.25    ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.16    ,  0.979998,  0.954111,  0.      , -0.25    ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.689167,  0.987036,  0.92411 ,\n",
       "        0.      , -0.25    ,  0.      ,  0.      ,  0.      ,  0.867052,\n",
       "        0.975287,  0.813456,  0.      ,  0.      , -0.25    ,  0.      ,\n",
       "        0.      ,  0.934405,  0.903144,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.977522,\n",
       "        0.216   ,  0.      ,  0.      ,  0.      ,  0.      , -0.25    ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      , -0.25    , -0.25    , -0.25    ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      , -0.25    , -0.25    ,\n",
       "       -0.25    , -0.25    ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      , -0.25    , -0.25    , -0.25    , -0.25    ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      , -0.25    , -0.25    , -0.25    ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      , -0.25    ,  0.615385,  0.81448 ,  0.98211 ,  0.236967,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.825   ,  0.868957,  0.912158,  0.494234,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      , -0.25    ,  0.802469,  0.529412,\n",
       "        0.      ,  0.939733,  0.856388,  0.      ,  0.      ,  0.      ,\n",
       "       -0.25    ,  0.857595,  0.853659,  0.589474,  0.558042,  0.      ,\n",
       "        0.      ,  0.      ,  0.      , -0.25    ,  0.910979,  0.938913,\n",
       "        0.584594,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "       -0.25    ,  0.      ,  0.829091,  0.394059,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.609023,\n",
       "        0.686546,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      , -0.25    ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      , -0.25    , -0.25    , -0.25    ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "       -0.25    , -0.25    , -0.25    ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 0:231][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.989669,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "        -0.25    ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "        -0.25    ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "        -0.25    ],\n",
       "       ...,\n",
       "       [ 0.      ,  0.918251,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      ,  0.999534, ...,  0.      ,  0.      ,\n",
       "        -0.25    ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[:, 232:373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274/1274 [==============================] - 2s 1ms/step - loss: 0.1182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261a7d42828>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create two hidden layer and output layer\n",
    "\n",
    "input=layers.Input(shape=(373,))\n",
    "x=layers.Dense(64,activation=\"relu\")(input)\n",
    "x=layers.Dense(32,activation=\"relu\")(x)\n",
    "output=layers.Dense(1,activation=\"linear\")(x)\n",
    "\n",
    "# fit the model\n",
    "model=Model(input,output)\n",
    "model.compile(optimizer=\"adam\",loss=\"mae\")\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 0.26799148792898464.\n",
      "The validation RMSE is 0.2399578750867347.\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"The test RMSE is {}.\".format(rmse))\n",
    "\n",
    "pred2 = model.predict(X_val)\n",
    "rmse2 = np.sqrt(mean_squared_error(y_val, pred2))\n",
    "print(\"The validation RMSE is {}.\".format(rmse2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一些参考的code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABAlElEQVR4nO3dd3zU9f3A8df7Vi6DDaICAiogiAgYEBWVukqtglp3pWC1ViuCo3W0/lyldVVU6mjdVq2i1IHWVhRrW60IiSAICKIgBtmB7Mut9++Pu8QQMy65u9wl934+yIO77/x8L5fv+/vZoqoYY4zJXI5UJ8AYY0xqWSAwxpgMZ4HAGGMynAUCY4zJcBYIjDEmw7lSnYDW6Nmzpw4YMCDVyTDGmHalsLBwh6r2qr88IYFARCYC9wNO4DFVvaPe+mnA3cCm6KIHVPWx6LqpwI3R5bNU9enmzjdgwAAKCgoSkXRjjMkYIvJVQ8vjDgQi4gQeBE4EioAlIjJfVVfV23Suqk6vt2934GYgH1CgMLrvrnjTZYwxJjaJqCMYC6xT1S9V1Q+8AEyOcd/vA2+ranH05v82MDEBaTLGGBOjRASCPsDXdd4XRZfV9yMRWS4i80SkXwv3NcYYkyRtVVn8OvC8qlaLyM+Bp4HjWnIAEbkEuARgv/32S3wKjTEpEwgEKCoqwufzpTopHYLX66Vv37643e6Ytk9EINgE9Kvzvi/fVgoDoKo767x9DLirzr4T6u37XkMnUdVHgEcA8vPzbYAkYzqQoqIiOnXqxIABAxCRVCenXVNVdu7cSVFREQMHDoxpn0QUDS0BBonIQBHxAOcC8+tuICL71Hk7CVgdff0WcJKIdBORbsBJ0WXGmAzi8/no0aOHBYEEEBF69OjRotxV3DkCVQ2KyHQiN3An8ISqrhSR24ACVZ0PzBCRSUAQKAamRfctFpHfEgkmALepanG8aTLGtD8WBBKnpZ9lQuoIVPVN4M16y26q8/oG4IZG9n0CeCIR6TDGGNNyNsSEMcakwLJly3jzzW+fn+fPn88dd9zRxB7JY4HAGGNSoH4gmDRpEtdff31K0mKBwBhjgGeffZaxY8cycuRIfv7zn/PRRx8xYsQIfD4fFRUVHHzwwXz66ae89957HHPMMfzwhz9kyJAhXHrppYTDYQAWLFjAEUccwejRoznrrLMoLy8HYMmSJRx55JEceuihjB07lpKSEm666Sbmzp3LyJEjmTt3Lk899RTTp0cGX9iwYQPHHXccI0aM4Pjjj2fjxo0ATJs2jRkzZnDkkUey//77M2/evIRce7scdM4Y03Hd+vpKVn1TmtBjDtu3MzefenCj61evXs3cuXP54IMPcLvd/OIXv2DNmjVMmjSJG2+8kaqqKi644AKGDx/Oe++9x+LFi1m1ahX9+/dn4sSJvPzyy0yYMIFZs2bxzjvvkJuby5133sns2bO5/vrrOeecc5g7dy5jxoyhtLSUnJwcbrvtNgoKCnjggQcAeOqpp2rTc8UVVzB16lSmTp3KE088wYwZM3j11VcB2Lx5M++//z6fffYZkyZN4swzz4z787FAYIzJeAsXLqSwsJAxY8YAUFVVxV577cVNN93EmDFj8Hq9zJkzp3b7sWPHsv/++wNw3nnn8f777+P1elm1ahVHHXUUAH6/nyOOOII1a9awzz771B67c+fOzabnww8/5OWXXwZgypQpXHvttbXrTjvtNBwOB8OGDWPr1q0Juf6MCwRbS63nojHpJhRWAqFI8cqvTx6alHPUHL8hwVCYC6b8hN/9/vd7LN+8eTPl5eX4AwHKKirJzc0lGAoDUnu8UDiMKgSCIY4/4QSefe6vexxjxYoVkfX1zh8Khwmr7nGcuu8DoTA4wnu+B7KysmqPoZqYvrVWR2CMyXjfO+44Xnn5b2zbtg2A4uJivvrqK35x2aXcfOutnHfe+fz6hm8rcpcsWcz69esJh8O89OKLHDn+KA4fN44P//c/1q1bB0BFRQVr165lyJAhbNmymYIlke5SZWVlBINB8jp1oqysrMH0jDviCObOfQGA5//6HEeNH5/My8+8HIExxtQ3bNgwbrntNk7+wUTC4TBut5tTT52E2+3mvPPOJxQKccz48fzr3XdxOBzk54/hyhlXsO6LL5gwYQKnnXY6DoeDxx5/gikX/Jjq6moAbr3tNgYPHsxzf32eK2fOpMpXRbY3m38uWMCECd/j7rvuIv+w0Vx73XV7pOe+++fws4suYvY999CrZy8effzxpF6/JCpr0Zby8/O1tRPTWNGQMeln+9dfMuSgg1KdjJj8+733uHf2Pbw6//U2P7fbGXshzurVqxk6dM9iNhEpVNX8+tta0ZAxxmQ4KxoyxpgWOHbCBI6dMCHVyUgoyxEYY9JCeyymTlct/SwtEBhjUs7lyaJ4Z7EFgwSomY/A6/XGvI8VDRljUq5zj97s3rmVHTu2pzopac3piG146ZoZymJlgcAYk3JOl4tuvW268ub07hz7U35LWNGQMcZkOAsExhiT4RISCERkooisEZF1IvKdAbVF5GoRWSUiy0VkoYj0r7MuJCLLoj/z6+9rjDEmueKuIxARJ/AgcCJQBCwRkfmquqrOZkuBfFWtFJHLgLuAc6LrqlR1ZLzpMMYY0zqJyBGMBdap6peq6gdeACbX3UBV/6WqldG3i4DYq7ONMcYkVSICQR/g6zrvi6LLGnMR8I86770iUiAii0TktMZ2EpFLotsVbN9uTcyMMSZR2rT5qIhcAOQDx9ZZ3F9VN4nI/sC7IrJCVb+ov6+qPgI8ApFB59okwcYYkwESkSPYBPSr875vdNkeROQE4DfAJFWtrlmuqpui/38JvAeMSkCajDHGxCgRgWAJMEhEBoqIBzgX2KP1j4iMAv5MJAhsq7O8m4hkRV/3BI4C6lYyG2OMSbK4i4ZUNSgi04G3ACfwhKquFJHbgAJVnQ/cDeQBL4kIwEZVnQQMBf4sImEiQemOeq2NjDHGJFlC6ghU9U3gzXrLbqrz+oRG9vsfcEgi0mCMMaZ1rGexMcZkOAsExhiT4SwQGGNMhrNAYIwxGc4CgTHGZDgLBMYYk+EsEBhjTIazQGCMMRnOAoExxmQ4CwTGGJPhLBAYY0yGs0BgjDEZzgKBMcZkOAsExhiT4SwQGGNMhrNAYIwxGS4hgUBEJorIGhFZJyLXN7A+S0TmRtd/JCID6qy7Ibp8jYh8PxHpMcYYE7u4A4GIOIEHgR8Aw4DzRGRYvc0uAnap6oHAvcCd0X2HEZnj+GBgIvBQ9HjGGGPaSCKmqhwLrFPVLwFE5AVgMntOQj8ZuCX6eh7wgEQmL54MvKCq1cB6EVkXPd6HCUjXd9z6+ko++Xp3Mg5tjDFJd2i/rtx86sEJP24iiob6AF/XeV8UXdbgNqoaBEqAHjHuC4CIXCIiBSJSsH379gQk2xhjDCRo8vq2oKqPAI8A5Ofna2uOcfOpB7O11JfQdBljTFvp3dmblOMmIkewCehX533f6LIGtxERF9AF2BnjvsYYY5IoEYFgCTBIRAaKiIdI5e/8etvMB6ZGX58JvKuqGl1+brRV0UBgELA4AWkyxhgTo7iLhlQ1KCLTgbcAJ/CEqq4UkduAAlWdDzwOPBOtDC4mEiyIbvcikYrlIHC5qobiTZMxxpjYSeTBvH3Jz8/XgoKCVu1rdQTGmPYq3joCESlU1fz6y61nsTHGZDgLBMYYk+EsEBhjTIazQGCMMRnOAoExxmQ4CwTGGJPhLBAYY0yGs0BgjDEZzgKBMcZkOAsExhiT4SwQGGNMhrNAYIwxGc4CgTHGZDgLBMYYk+EsEBhjTIazQGCMMRkurkAgIt1F5G0R+Tz6f7cGthkpIh+KyEoRWS4i59RZ95SIrBeRZdGfkfGkxxhjTMvFmyO4HlioqoOAhdH39VUCP1HVg4GJwH0i0rXO+l+p6sjoz7I402OMMaaF4g0Ek4Gno6+fBk6rv4GqrlXVz6OvvwG2Ab3iPK8xxpgEiTcQ9FbVzdHXW4DeTW0sImMBD/BFncW/ixYZ3SsiWU3se4mIFIhIwfbt2+NMtjHGmBrNBgIReUdEPm3gZ3Ld7VRVAW3iOPsAzwAXqmo4uvgG4CBgDNAduK6x/VX1EVXNV9X8Xr0sQ2GMMYniam4DVT2hsXUislVE9lHVzdEb/bZGtusM/B34jaouqnPsmtxEtYg8CfyyRak3xhgTt3iLhuYDU6OvpwKv1d9ARDzAK8BfVHVevXX7RP8XIvULn8aZHmOMMS0UbyC4AzhRRD4HToi+R0TyReSx6DZnA8cA0xpoJvqciKwAVgA9gVlxpscYY0wLNVs01BRV3Qkc38DyAuDi6OtngWcb2f+4eM5vjDEmftaz2BhjMpwFAmOMyXAWCIwxJsNZIDDGmAxngcAYYzKcBQJjjMlwFgiMMSbDWSAwxpgMZ4HAGGMyXFw9i9uj3p29qU6CMcakFcsRGGNMhrNAYIwxGc4CgTHGZDiJTCzWvojIduCrVu7eE9iRwOS0F5l43Zl4zZCZ123XHJv+qvqdKR7bZSCIh4gUqGp+qtPR1jLxujPxmiEzr9uuOT5WNGSMMRnOAoExxmS4TAwEj6Q6ASmSidedidcMmXndds1xyLg6AmOMMXvKxByBMcaYOiwQGGNMhrNAYIwxGc4CgTHGZDgLBMYYk+EsEBhjTIazQGCMMRnOAoExxmQ4CwTGGJPhLBAYY0yGs0BgjDEZzgKBMcZkOAsExhiT4SwQGGNMhnOlOgGt0bNnTx0wYECqk2GMMe1KYWHhjobmLE5IIBCRicD9gBN4TFXvqLd+GnA3sCm66AFVfSy6bipwY3T5LFV9urnzDRgwgIKCgkQk3RhjMoaIfNXQ8rgDgYg4gQeBE4EiYImIzFfVVfU2nauq0+vt2x24GcgHFCiM7rsr3nQZY4yJTSLqCMYC61T1S1X1Ay8Ak2Pc9/vA26paHL35vw1MTECajDHGxCgRgaAP8HWd90XRZfX9SESWi8g8EenXwn0RkUtEpEBECrZv356AZMcuGArjC4SoqA7iC4QIhsJtcl5VxR8MU+kP1p47FLapRY0xidVWlcWvA8+rarWI/Bx4GjiuJQdQ1UeITtacn5+f9LthMBSmMhDC5w/R0MkcInTOdpHlcib83KpKWXWQKn+owfVOh5DjcZLtdiIiCT+/MSazJCJHsAnoV+d9X76tFAZAVXeqanX07WPAYbHu29YCoTC7K/3srPBT1UgQAAirsrsyQKkvgGri4pI/GK49d2NCYaXMF2R7WTVlvgBhyyUYY+KQiECwBBgkIgNFxAOcC8yvu4GI7FPn7SRgdfT1W8BJItJNRLoBJ0WXtblQWCmpDFBc4ac6GHvRT5U/RHGFPyHBwBcIsavSH3PxjwKV/hA7yqupqA4mNCAZYzJH3EVDqhoUkelEbuBO4AlVXSkitwEFqjofmCEik4AgUAxMi+5bLCK/JRJMAG5T1eJ409QS4bBS7g82WgQUi2BYKa0K0iXH3ep0BENhSqsCrdpXgfLqIJX+EHlZLrI9iS+uMibZVJVgWPd4EBIBpwhOh1gxaBJJe3yKzM/P13j7Eagqlf4QFf4gifoI8rJc5Ga1PLaGw0pxC3ICzXE5hDxvcuovTPsWCIWpDoYJhZRgOExIFSFyo3WK4PU42vx74w+GqagOEgiFm3wYc4jgcghOZ+R/hwgikeU1VEFRwuFI8W1Y93xd91hulwO3U/A4HSkNMqpKIBRJnyMa9BxCUtIkIoWqml9/ebvsWRyPZASAGuXVQVxOafEfUqkvkNDWQMFwpP7C4wyR53XhdtpIIplKVfGHwvgCYaqDoQa/84oSDikBwBcM4XaGyM1yJj0gBENhyquDMRfFhlXxhxQarz5rgcjnApFcR6csd5vmpGvuQ5X+0B4BqoYALqcDTxsFq4wLBDvK/Q1+8IlSWhWkZ17svzRfINSiOomW8IfCFFf4yXI5yM2ygJApYrn5NyXSYCJMjidMJ2/rizub4g+G2V3lT/jDWGuoRh7GqgIhOrXBg5MvEKLMF2zyPqREfg+BOsEqy+kkJ8uZlPRlXCBIdlFYOBrpYykiUo20/km26mCY6qAFhI4sHI7c/KsDYapDLb/5N6QyWm/WOcHBwB+MtMxLgxiwh0AozK4KP11zPHhcyfkbKfUFmmwR2BjVaG7NJRYI2ouK6iDZbicOR9O5gsayhclSExA8zkhASNaX3SSXaqRCNRBSAuEwgWCYYJKaENfctBIVDNI1CNRQYHeVn245noTfcMtaGQTaggWCJFCg3B9s8o8nHFYq/MnPDTTEHwrjr4wEBKtDSD1VjVZyRl8TyVmqRp4EQ7WVnt9tVdMWqvwhXA4hxxPf7SIcVkqqAmkbBGqowq5KP91zPLgS9LdR5gtQmaZBACwQJE2VP0SO29noFykZldUtVVOHkO1xkudxNZuDSVfhcPTJOBS5SYbD0Rtn9PNVonfZlkj0R6FNvk175b4gHqcjrhtjc+Xi6UQVdlcF6JHribuS1hcIpXUQAAsESVVRHaJLznf/cEJhTassYpU/hC8QorPXjdfdPpqchsKKLxCiKlnjL7WP+1WbUaDUF6R7rqdV+/sCIXzB9PnOxyIUVsqrg3FVmIfDSqmvdf2D2pKVCSSRL9jwTarSH0y7+4wqlFQlfsiMRKvpAb6jvJry6qANwteGAqFIe/+Wai83w4ZU+kO1LXdaI/L3lMAEJYkFgiSrrFcPoKpUBdL3yahmyIx0G79IVamoDrKzvLrdPVl2JBXVwRaPvltWnfpi0HiUVrXu4SiZTcMTzQJBklUFQnt8iXyBcNr/UQTDyq7K9AkGGh3gr7w6/XJSmUaBihYUa9YM4d6eBcPaomuG9pcLskCQZKrgq/MlqvQHSftIQPoEg3BYKa7w1/YCNanXkjk5KqrbdxCoUVkdbNHfQjo0BmkJCwRJlnv7LLj6KohOMhMMhcm74VeR5WmuJhikqs4gFB2DKVlt5E3rxXKDD4bCHaYYT4HKGHM24TRrDBILCwTJpIqU7Cb7oQcIzbySqupgJAg8/CBSsrvd5AxK26D3c32R4qDEDcRnEssXbD5X0FFyAzVizRVUpGFjkOZY89EkUVUKv9rFspN/wefZo/m8Uugy/U8cssXB4Bl3MvZXl7BXOxlW1xcI4XE62nRQrlJf0HICaa6x5tHQsXIDNWpyBXlNDB/THnMDYIEgKT7fVsa9b39O4Ve7EKD/3gM57L9vsiu7MwsGjWNudhey/vQhU8b1Z8oR/dtF2/0yXwC3UxLW07IpNf0aTHrzBUPkhhruNNnRcgM1Kv1BcpoYPqY95gbAAkFC+QIh5iz8nFeWbqKT180vTxrMycP3pvctN5D7+oNA5Kli5eXXct+YM3ns/fXM/+Qbrp04hKMH9Upt4puhRPoZdE9AT8umBEJhytpRa4tMVxkI0bleIAiFtcPlBmqoNp4raK+5AUhQHYGITBSRNSKyTkSub2D91SKySkSWi8hCEelfZ11IRJZFf+bX37e92F3pZ/pfl/Lyx5s4K78f8y49grMO6xsJAg8/CDNn4vcHqbzscoY/eBf3f/Q0f7pgNF2y3fzqpeW8sHhjqi+hWcGwJr2rfGk7GIvGfMvnD32nMUE695NJhEp/w9PCVgVaP8thqsWdIxARJ/AgcCJQBCwRkfmquqrOZkuBfFWtFJHLgLuAc6LrqlR1ZLzpSKVNu6qYOXcpW0uq+f0Zh3DcQXvVrtMuXQlMvwL3vffiEaHkjj/ULh+1Xzcem5rPTa+t5N53PmdLqY8Zxw/aY8aldBPryKqtUem3eoH2RoncAGsGpFNtv0/FsVKNjORbv0g33ccTakoiiobGAutU9UsAEXkBmAzUBgJV/Ved7RcBFyTgvGlh/Y4KLnu2kJAqD5w/ikP7dd1jfcUNN5Kd64nMLAFkZ7kov/3u2vdet5PbzziE+95Zy/OLv2ZXRYCbJw1L22CgRHqKdslO7Bj14ei4Lqb9qaoO1gaC6mCYcDhc+/3uqCr9oT0CgS/QtkPKJ1oiiob6AF/XeV8UXdaYi4B/1HnvFZECEVkkIqc1tpOIXBLdrmD79u1xJThRtpb6mPnCUkSER6fkfycIAHicDpx1ylC9Lsd3/kicDuHqEwdz2bEH8M+VW5i9YG1aj/fjC8Q3/kpDyttZBxwTkXv7LLzX/RJ/tDiotol0O+gnE49AKEygTj1IlT/ULpqDN6ZN+xGIyAVAPnB3ncX9o5Mpnw/cJyIHNLSvqj6iqvmqmt+rV+orVksqA8x4finl1UHuP3ckA3rmNrhd/SaXLqejwfH/RYRpRw3gx4fvx0uFRTz5wYZkJDthEjmzWiAU7vDFCR1StJ9M7sMPoldeRTAYwnPtNe2qn0xr5d4+i/CVkY6iwVAYfzDUrgNgIoqGNgH96rzvG122BxE5AfgNcKyqVtcsV9VN0f+/FJH3gFHAFwlIV9JU+UNc9eIyvtnt4/5zRzK4d6cGtxMgq4FZwLxuR6NP1NOPO5BdlX7+/J8v6Zrj5ozRfROZ9IQJRMeQSUTT1/IUdFgz8ft6VxWLz5rJ5qyDKCraQcmF97Lfbi99Zt5Lv/NP56iQ4nF1wCKiaADMevhB1ClU3XF3bUfRissujwTAdlY0lohAsAQYJCIDiQSAc4k83dcSkVHAn4GJqrqtzvJuQKWqVotIT+AoIhXJaSusyq2vr2T15lJuP+MQRvfv1ui2WS5ng00tvS4nZTR883OI8JuTh1JSFeDut9awb9dsxu3fI2HpT6T65aStEQiFbRyhdiSsyodf7OSlwiI+/GInAN68A9g/L0xnXwVL+h7Ma9690Jc/pVuOm0kj9+X0UX3Yp0t2ilOeOOX+EKtn/B87XXuzY9FSOh8xif67vmGvX1xD3u9uS2rz6mSRRJRFi8jJwH2AE3hCVX8nIrcBBao6X0TeAQ4BNkd32aiqk0TkSCIBIkykmOo+VX28ufPl5+drQUFBq9K6rdQXVxOvP//7C574YAMzjx/E+Yfv1+S2XbIbn+hlVzMDqVVUB7nkmUK2lPh4fGp+o0VPqdY1x02Wq/XBYHelv90M1Zvp1m4t43d/X81nW8rokevhjNF9OHn43gy68ybyHn6wdrviy67gvz+7lr8t3cT7n+9ARJgyrj8/HT8gru9KKoXCykfrd/La0m/477odjQ59sl/3HE4btS8/PGQfuua0bhKfpnTyuuKaMlRECqNF8XsuT+dKycakKhAsWLmF/3ttJaceug+/OXlok5FfBHrlZTW6TZU/1OwwtZtLqrjwySXkZrl4YuoYuuQktqVOInicDrq1ctaqYCjMzgp/glNkEs0fDPPEB+v5y4df0dnrYsbxgzhxWG/cDqktEgleMQPX/fdRNX0G2Q89QMVll1N++91sKa3mkf9+yd+Xb6Zf92x+/YOhTeai042qsmDVVh761xdsKfXRLcfNDw7Zh0P7dOHAvzzMoEfnUOrN5atu+7Jy8vm8ceCRLN9UgtspTDp0Xy499gA6J7CFnQWCOlIRCFZ9U8qlzxYydJ/OPHD+qGYnfPe6nU02sQyHle3l1Y2ur7GiqITLnivkkD5dmHNe8+dNhW45HjwN1IU0p6Qy0GF7oHYUm0uquG7eCtZsLePkQ/bmyuMH7/FAknv7LBwlu8l+YA7icFBZHUCvugrt0pWKG26s3W7x+mLu+MdnbNpdxYVHDuBnx+yPM83nyP5yezl3v7WGjzfuZsjenZh6RH+OGdxrjwDIzJlU3nk3etVVtXUEy6++mZcKN/Hasm/onB0JnD8YvndCiowsENTR1oFgW5mPC59cgtvp4MlpY2J6Am6qWKhGc8VDNf7x6WZumb+KySP35YYfHJR2ZZBZLkeLs8GWG0h/hV/t4tcvryAYVm4+dRjHDG64tV6220Hn7MjvPxxWtpf5Gqws9QVC3LNgLfM/+YZx+3fntknD0zKXG1bluUUbefjfX5DrcXLZhAOYPLLPHoEr9/ZZeMpK8fzxfsIK28t85N3wqz0C4NqtZdz5z8/4dFMphw/szi2TDm71nM81LBDU0ZaBwBcI8fNnCtlYXMljP8nngL3ymt2nuWKhGrEUD9V46L11PP2/r7jqhEGcO7bpuolU6J7raVFupaQqYAPLpbF5hUXMXrCWft2zufvMQ9mvR06j29b/3TdX7/Pq0k38YcEaeuZlcfdZIxi0V8Ot7lKhuMLPra+vZNGXxRx30F5c+/0hjT749chx44rWeeyu9FMdCH0nAIZVeeXjTdz3zud0yXYz6/ThjGygv1GskhUI0q+cIY2oKre9voo1W8r47eThMQUBaLy10He3i/3jv/TYAzh2cC/uX/g5//tiR8z7tZWWdK8PhzXyR2PSTliVOQs/5+631nDkgT14fNqYJoOAyyHfeQBoLid82qg+/HnKYQRDyiV/KeSDdenxfV66cRdTHv+Ij7/azXUTh/D704c3GgRcDqkNAhC95gb+5h0i/Oiwvjw+LZ8st4NfPPsxz330Vdp1GLVA0IQ///tLFn62jcuPO5Dxg3rGvJ/XHdvH6nAInhifoh0i3DJpGAfulcdvXvmUNVvKYk5PW6gOhGKeyq89D87VkfmDYW56bSXPfbSRMw/ry50/GtHk2PvQ8E0/y+Vothn9wft24YkL8+nXLYdfvvQJLy75uukdkkhVeangay7/61KyPU4en5bPGaP7NvkwV7+jaHPXPLh3J56+cCxHD+7JnIXr+O3fV+NPo9ZyFgga8bfCIp783wYmj9yXC5ppJlqXCDHf3KH5p6e6cjwu/nDWoXTyurhy7jI27aqKed9kqxl8LBbteXCujqrMF2DmC0t5e9VWLv/eAfzypMExVeY29P0VkZi+13t18vKnKaMZP6gn97y9lrv++VnMcyEnii8Q4rd/X80fFqzliP178OS0MY12EK0hRPoC7bEshmvO87q4/YxDuHj8QP6+fDPT//oxu9KknswCQQPeW7ONu99aw9GDenLtxCEtqpyNtVjo2+0dtKTqt3dnL/efO4pgKMyMF5ZSnCZfJIgtELT3wbk6oq2lPn7+TCHLi0q4ddLB/OSIATF9hz1OR6PBov6NsjE5Hhd3nDGCKeP687ePNzHjhWWUVLbNfBSbdlXxs78U8Pflm7l4/EDuPmsEnbzNV157XI4GR9/NjiH4OUT42TH7M+u04Xy2pYwLn1rCF9vKW5X+RLJAUM/HX+3i/15dycF9OjPrtOG4HC37iGItFqrhcEiLm14O7JnLPWcfyvayaq5+cVnaTOQSCivVzTQHtTGF0su6beVc9HQBW0p93HfOSCYO3zvmfZt6Ava4HDGPoOt0CNOPO5CbTx3G8qLdXPjUEj7fltyiz/+s3c5PnljM5hIf95x1KD87Zv+Y09vYdbubCIz1nTisN3+64DACoTAX/6WA91NcT2KBoI6CDcVc9eIy9u3q5Z6zDm3x8AktLRaq0ZreliP6duX3px/C51vLufy5peyuTI+cQVM3+qANJ5FWPli3g0ueKQCFP085jDEDu8e8r9D8Q09LH4pOPmQfHr7gMKqDIX76ZAEvFXyd8EpVXyDE7LfX8qt5y+nTLZu//HRsi+r/RJpu5NGSe8awfTvz5IVj6Nc9h1+++ElKK5EtEEQt+nInV7/4Cft2yeahH49uVffwlhYLfbtfy4qHaowf1JO7zxrBhp0V/OK5j9kZQwe1ZKsOhhst5620lkJpQVV5dtFXXPPiJ/TtmsPj0/Jb3IQzlu96LEUl9R3SpwvPXHQ4+QO68YcFkRt2ooo/lxft5oLHP2Lukq8567C+PPqTw9i3a8vGQPK6m75ubwtz93t18vLIlMP43kF7MWfhOm589VMqUjAvh/UjAP69djs3vvIp/Xvk8MfzRrV6yIR4xt2JtXNZQwo2FHPNS5/Qq1MWs88a2WRzv7aQ43F+p6xVVdleVm2thVKsyh/irrc+480VWzj+oL34v1OGfacFTCxi6TAJsLO8ulWzzqkqLyz5mgfeXUeW28GFRw3knPx+rerBvrXUxxPvr+e1Zd+wdxcvN/5wKPkDYs/91BVLL/riCn+L5+uIBOeNPPTeOvbrnsMdPxrBwAbGF7MOZXUkKhCEVXni/fU8+t/1DNunM/edO7LVM2/F2omsMS3pXNaQT77ezbXzluMPhbnl1IM5dkjq5mxo6LOI9/pM/NZsKeP/Xv2UjcWVXHz0QC4aP7BV39eWfNcrqoNxzTy3YUcFc979nA/W7aRP12x+ckR/jh+6V0yVut/sruL5xRt5ZekmVOGM0X249NgDyG2mSWxjHCL06pTV7HaV/mCr5+so2FDMja9+SlUgxIzjBnHG6D57fM4WCOpIRCCoqA5y6+ur+Pfa7Zx8yN5cN/GguIZUbm5soebEOvZQU7aU+Ljh5RWs2lzKT47ozyXH7J+ysYnqPzG25inJJEYorMxd8jUPvbeOrtkebpk0rNVPxNCy73oorOxIQJHloi938sd317FuWzkep4OjB/Xk8P2707dbDn27ZeNxOthZ4WdnRTUrikr499rtrN1ajlOEUw7dhwuPGhD3UNgN5XQbEu/f8rYyH7PeWM1H64sZO7A7N/5wKL07ewELBHuINxB88MUO7vrnGraVVjPj+AM5Z0y/uMfviTWr3JR4iodq+INhZr+9lleWbqJ/9xyu+f5gDh/Y9vMZeBxCt7zI01MwFI7UX6TZGEmZ4JOvd/OHBWtYu7WcYwb35MaTh8U9vk9Li0AT8b2GSPHJ6s1l/OPTzSxYuZXdVQ3nMAU4pG8XJgzpxXEH7ZWwuRB65HpwxfhgFe/w6qrKK0s3MWfhOkRg2pEDOHdsP3rmZVkgqNHaQLCtzMdvXl7B26u3MaBHDr8+eWiD8wy3VLzFQjUSWXzywbodzH57LUW7qpgwpBcXjR/YbEeZRMm9fRZSshvvH+fgdDoorfLjvObq74xIaZJnY3ElT7y/nn98uoW9OmUx8/hBHD90r7i/o7EWj9SVjGLBUFjZWuqjaFcVRbsqCYaUHnkeuud66N8jN+7B3epzOYQeebFfty8QoqSRQNUSm3ZVce87a/nv5zvYu7OXq08axJmj+zXYjyEWjQWCRMxQ1m5c9uzHLC/azSXH7M+Ucf1bVfHUkNa2FvrucRJXjHPUgT3JH9CN5z/6mif/t5731mxnRN8unHlYX44e1DOup4om1ZnH1u904Lj/PlzXXE1OO57Gr71QVVZtLuWZD7/ivTXbcTsdTD2yP9OOHJCw33dLm4TCt63iEvnI6XQI+3bNZt+u2YxtQbPX1mppbj9R19ynWzZ/OOtQCjYUM2fhOq6dt4LBvTvHNXBdQzIqR/DpphKq/EH265HY2b7inaWrrmTM2FVaFeDvKzYzr7CIol1VuBzCiL5dGDuwO4N7d6J/jxz26ZLd4vHhg6Ewlf4QVYEQVf4Q1cEw/mBkIu+sR/+E543XAXCGQwQnTcZ/2eV4PU6y3ZGfPK+r3c5YlU427qzk7dVbeXvVVtbvqKCT18WPRvfl7Py+LXqKjUVLR5mt0d7nnuiVl9Xip/BEj7AbVmXVN6UcP7R3q4+R1KIhEZkI3E9kqsrHVPWOeuuzgL8AhwE7gXNUdUN03Q3ARUAImKGqbzV3vlROVVmfSKQtcKIkKkvZkLAqH3+1i0VfFrN4fTFrtn7be9PtFLrmeOiU5SLP66r9YxcgGO0xXB0IUxUIRW7+/lBCyn09TgedvC665rjpku2ma46Hbjluuud66JbjoVvut++75njo5HXF3AO0I6ryh9iws4LPt5az9OtdLN24m80lPgQY2a8rJw7rzcThe7e6ZUxTWlo8Ulcyv9fJ1tpZ+KqDIXYneLiMZFUWx/1tEREn8CBwIlAELBGR+aq6qs5mFwG7VPVAETkXuBM4R0SGEZns/mBgX+AdERmsqu3m0SHeCuL6kpGNruEQIX9A99oWIyVVATbsqOCr4kq+Lq5kV6WfMl+Qcl+QYFhRVZTIDaBrjocsl4Nst5Mcj5PcLFft6xyPiyy3A6/LicflwO0U8h59mJxXXgYg5HBQMfkMSqZdTHVI8UWDSXl15FylvgAllQF2VwX4cns5xZV+Sqsabn7nFKFztosu2W46Z0eCR16Wi9wsF3lZrmh6nHjdkZ8slwOPy0GWy4HLGUmb2xEZCqDmxyGCwxH5fITIAGKR/0EQov+g7rImKIpq9Heoe74PqxIKa+3/wZASCIcJBCOfiy8YipapRz6bXZV+tpdVs72smi2lPjaX+GrP0y3Hzch+Xfnx4ftxzOBetS1LkiWe73rN6JztsACiVf0sIFJk7JBguxhbKxGPDWOBdar6JYCIvABMBuoGgsnALdHX84AHJFKoPhl4QVWrgfUisi56vA8TkK42EevgWrESEbJczjbJRnfJdnNov64JqTCvpVo7jZ9/+hW4o/PY5jxwGxWhnZTffndMdQTBUJhdlQF2VfrZXRmguMLP7ujrXZV+Sn1BSqsCbCnxUV4dpMIfpMIXItQO/uhawuN00LOTh155WYzo24VJh+7LwJ65HNArj37ds9t0trp4AkHN6JztbawpIb66O6/b0S5G201EIOgD1B1MvAg4vLFtVDUoIiVAj+jyRfX27dPQSUTkEuASgP32S48ZuhzS8gHjYpHldrTf8lSRSOugyy7He999iMNB6J7ZVADapWvMFcUup4NenbJa1EJFVakOhmtzHL5ApPiqOhCpuwiGFX8oMgRGKKyEap/OI22/w/rtk7vWf93g+Zq+nPq5C6BODkQik5s4BJfTgcfpwOt2kBWtP+nkddHZ68brdqTF1KRNjTQaK6+r/QWCrGaGlGhOttuZMYGgTajqI8AjEKkjSHFygNa1oIhFe85GA1TccCNZTiE3Ws+Q7XGxM8acQDxqnjq9biddUzvKRoeTiCJQjysSTEKtGHIiVVozXlJdLqcDl0NaNcxGW0rEnWwT0K/O+77RZQ1uIyIuoAuRSuNY9k1bia4fqFFTPNSeeetUaLmcDtzt/HoyWSwjjcYqWX8zyZCoHH9r6xjaUiJ+u0uAQSIyUEQ8RCp/59fbZj4wNfr6TOBdjTRXmg+cKyJZIjIQGAQsTkCaks7ZwFytiZSs3EZbaGio3nifrEzqxFs8Uld7+h4k6gae6HrEZIi7aCha5j8deItI89EnVHWliNwGFKjqfOBx4JloZXAxkWBBdLsXiVQsB4HL20uLoWQ/2bSnFgf1ZTdw4/C6HZT5ktMayiRXIm/ezug83e1hXopEXbfDIWS5HAnvH5RICakjUNU3gTfrLbupzmsfcFYj+/4O+F0i0tGW2uLJpr20OKivoc9GRMhyOxPawcYkn7MVM+g1J9vjxF+VvjdFSEzleF3ZHmfHDwTpIBAIUFRUhM/na3K7RFRUCVCcwC9JY1QjLVrak6Y+m0Rcj8uTRecevXG6OsxXN60l44GnPTSGSHS5frrn8DvMX1NRURGdOnViwICmJ95OxFDIzmjzv7YQDIXbVXFKc59NPNejqhTvLGb3zq10691gK2OTYMkoAhWRtG5W2dx0lK2V7XGmZPaxWLTfGsl6fD4fPXr0aJM2123ZrLu9DafQXICM53pEhO49uhP0p35KzkyQ5Ups8Uhd6Vxp3FAdV6KOm646TCAA2iQIOKRtzlOjPcWBWG7y8V5POnSuyhTJbBARGe4jPW8/ybphO6OVxukoPVOVxtr6CV1EaKNSqLjFks72dD2ZzBHtnJdMOWnYvt7jdMQ8+UxrpGs/CgsELVAzZECbn7eRcy5btox/vPltY63XX5/PXXfe2VbJ2kNLPpv2VtyVidriJp3lcqTddyHZnb/S8ZrBAkGLpOoXWDMqZn3LP1nGP//5j9r3p546iWuvu67tElZHSyrPpZHrMelBaJvybBFJq1yB05H8XFC6XXONDtNqqK5bX1/Jqm9KG1zX2hYrQ/fpxC2nHtzkNs8++yxz5szB7/dz+OGH89Of/pSf/exnLF68mFAoxNixY5k7dy47duzgpptuolOnTqxbt47vfe97PPTQQzgcDhYsWMDNN99MdXU1BxxwAE8++SR5eXkUFhRw5ZVXUlFZQZYni3+89Ra33nILVVVVfPDBB1x73XX4qqooLCzk/jl/ZMOGDVxy8cXs2LmDXj178ejjj7Pffvtx0U8vpHPnzhQWFLJ16xZ+f8cd/OhHZ7byU4kQWh4kHSIdbqTQjsLrcbZZq7hsd6QlTTp8E3KTNWtfPel0zTUsRxAjQZos+li9ejVz587lgw8+YNmyZTidTtasWcOkSZO48cYbufbaa7ngggsYPnw4AIsXL+aPf/wjq1at4osvvuDll19mx44dzJo1i3feeYePP/6Y/Px8Zs+ejd/v57zzzmX2vfdS+PFS/rlgAbm5udx8yy2cdfbZFBR+zNlnn7NHeq6cOYMLfjKFj5cu47zzz+OqK2fWrtu8eTPv/ec/vPLafG789a/j/mxak1NqqxuNabmcNizHdjgEbxo8IYu03bAu6XLNdXXIHMHNTTy5t7YfgauZG9fChQspLCxkzJgxAFRVVbHXXntx0003MWbMGLxeL3PmzKndfuzYsey///4AnHfeebz//vt4vV5WrVrFUUcdBYDf7+eII45gzZo17LPPPowdO5awKp07d242vR8tWsRL8/4GwI8vmMIN119fu27S5Mk4HA6GDRvG1q1bW/ZBNKC1JWZOyxWknWRXljYk1+NK+fDUOR5Xm9b/pcM119UhA0GixdJkVFWZOnUqt99++x7LN2/eTHl5OYFAAJ/PR25uZL7k+scTEVSVE088keeff36PdStWrKhNRyJ6GmdlfTvGf7xTlTqk6ZxSUyRZU7GZVsvJavsnVWeKx+IR2jYXBNH6iDaagCoWVjQUg1iKPo4//njmzZvHtm3bACguLuarr77i5z//Ob/97W/58Y9/zHV1KnIXL17M+vXrCYfDzJ07l/HjxzNu3Dg++OAD1q1bB0BFRQVr165lyJAhbN68mYKCAhwCZWVlBINB8jp1oqysrMH0jDviCObOfQGA5//6HEeNHx/vx9CgeEp4Ik1JrYgoXbgcqRv+PBlzLMeqLetE6kpF0G2M5QiaEWuzyGHDhjFr1ixOOukkwuEwbrebyZMn43a7Of/88wmFQhx55JG8++67OBwOxowZw/Tp02sri08//XQcDgdPPfUU5513HtXVkd6zs2bNYvDgwcydO5crrriCqqoqvN5s/rlgARMmfI+777qL/MNGf6e10H33z+FnF13E7Hvuqa0sTrREdK5LVC7HxC+VN2O305GSJ2Sh7SqJ63NHZ6ZLh5FYJd6igVTIz8/XgoKCPZatXr2aoUOHNrtvS+sIaqYWTKT33nuPP/zhD7zxxhut2j8YDqfFgF0uR+uLheoKhcMtCgZrPvuMXv32j/u85ltup4PuuZ6UpiEUVnaWV7dpaWFulou8FAbAQChMcYU/5u07eV3kxBG4RKRQVfPrL7eioSa0pllkW3CmQZoSOdRGOn7GmSaVN8MazjZuTeMQITfFrXdqckKpZoGgCckacGvChAmtzg1AepStJ/L86XA9mczjdCR8zoHWyvO42mx8rU7etm0p1Jg8ryvlHSzj+u2LSHcReVtEPo/+362BbUaKyIcislJElovIOXXWPSUi60VkWfRnZDzpSaS2HlyupVLZDD+elkKNHzOhhzMtkOdNfW6ghsMhbVJm72qDXsSxauucUEPifQy4HlioqoOAhdH39VUCP1HVg4GJwH0i0rXO+l+p6sjoz7I405Mw6f6EKiIpKyJKxk3bcgWp4XU7024U0ByPs9l+O/Hq5HUn9fgtledJba4g3m/AZODp6OungdPqb6Cqa1X18+jrb4BtQK84z5tUyXjiTQaHo+3H7HEm8bOxXEHbcojQKQ3qBuoTEbpku5P23c7NcqVNUVgNh0NSGpzi/TR6q+rm6OstQO+mNhaRsYAH+KLO4t9Fi4zuFZGsRnZFRC4RkQIRKdi+fXucyW4ijSSvbiAZ2jKtQnKHhkhlLicTdfK60naoD5fTkZQbo8fpSIuK8YZke5wpm6+g2bOKyDsi8mkDP5PrbqeRdqiNtvwSkX2AZ4ALVbWmDecNwEHAGKA70OjQmar6iKrmq2p+r14JyFDUb38ZfZ/oG+uGDRtqxxdKhliLVBIxZHWiPpuLL76YVatWNbiuJpfz2muvNrqNiZ/X5UybMvLGJPrGKAKds9OrSKi+Tl53SiajavZTVtUTVHV4Az+vAVujN/iaG/22ho4hIp2BvwO/UdVFdY69WSOqgSeBsYm4qOY4br0VxzVXfxsMVHFcczWu225tF0VCweCe8546YygiinfI6kQWCT322GMMGzas8XM5hPmvvcbq1RYIkkEkkhtoDzp73QmpwxCgS7Y77XP7TofQOQVFRPF+wvOBqdHXU4HX6m8gIh7gFeAvqjqv3rqaICJE6hc+jTM9zVOFkt0458ypDQaOa67GOWcOUlLy3ZxCC8yePZvhw4czfPhw7rvvvtrlwWCQH//4xwwdOpQzzzyTyspKAK6//nqGDRvGiBEj+OUvfwnA9u3b+dGPfsSYMWMYM2YMH3zwAQC33HILU6ZM4aijjmLKlCmMGzeOlStX1p7jhOOPo7CggCWLF3P0UUcxJv8wjhk/njVr1uD3+7n1llt46cUXyT9sNC++OJe/PP0UM2dcAURyLSedcAKjR43k+yeeyMaNGwG46KcXctWVMznm6PEceOABzJu3x6+vdt+DDjqowetbuHAho0aN4pBDDuGnP/1pbW/pCRMmUNMhMC8vj9/85jcceuihjBs3jq1bt/Lhhx/yxuuvc8N115F/2Gi++OKL75zXtI4AXbM9aVskVJ/DIXTNji8YCNAlx52y4TNayutu+9xavIHgDuBEEfkcOCH6HhHJF5HHotucDRwDTGugmehzIrICWAH0BGbFmZ7miRC+ZzahGTNwzpmD2+3COWcOOmMG3Htvq4fSLCws5Mknn+Sjjz5i0aJFPProoyxduhSANWvW8Itf/ILVq1fTuXNnHnroIXbu3Mkrr7zCypUrWb58OTfeeCMAM2fO5KqrrmLJkiX87W9/4+KLL649x6pVq3jnnXd4/vnnOeecc3jxxReByMB2mzdvZuzYMQw56CD+9e9/s6SgkJtvuYX/u/E3eDyeuIasfv+//+WNN97g+usbahTW8PX5fD6mTZvG3LlzWbFiBcFgkIcffvg7+1ZUVDBu3Dg++eQTjjnmGB599FGOPPJIJk2axJ133klB4ccccMABrfqdmO/qnO1Ou4rS5jgcQrec1gUDEeia42k3QaBGZ68LTxu25orrTKq6U1WPV9VB0SKk4ujyAlW9OPr6WVV112kiWttMVFWPU9VDokVNF6hqedxXFItoMNhj0X33xTWz+vvvv8/pp59Obm4ueXl5nHHGGfz3v/8FoF+/frVDS19wwQW8//77dOnSBa/Xy0UXXcTLL79MTk4OAO+88w7Tp09n5MiRTJo0idLSUsrLIx/LpEmTyM7OBuDss8+ufUJ/8cUXOfPMM3GIUF5WyrnnnM3IQ0fwy19eE1M5+0eLFnHeeecDkSGr/xfNhQCcftppOJ3OJoesbuj61qxZw8CBAxk8eDAAU6dO5T//+c939vV4PJxyyikAHHbYYWzYsKF2nc1kllh5Wa60rxdojEgkGOR4nDF/J1wOoVuOp90FPohcb9dWBr/WaH+fUCJEi4P2cNVVcRULNaWhIaddLheLFy/mzDPP5I033mDixIkAhMNhFi1axLJly1i2bBmbNm0iLy8PoHYIa4A+ffrQo0cPli9fzty5cznnnMhT/s033cRx3/seyz5Zziuvvka1z9fqdDtE8Hq9te8bG5eqoeuLldvtrt3e6XTuUf8hIjHVf5jm5XicKR1ULhFEIk0su+d6mnxadjoizU975GWlXR+JlhCJFIu1Rb1G+/2UWqtOnYDOmAHhMMycCfffH1cwOProo3n11VeprKykoqKCV155haOPPhqAjRs38uGHHwLw17/+lfHjx1NeXk5JSQknn3wy9957L5988gkAJ510En/84x9rj7ts2bJGz3nOOedw1113UVJSwogRIwAoKSmhb9++uBzCM08/XbttS4asHj9+fIs69DR0fUOGDGHDhg21Q2o/88wzHHvssTEfs1M0vTXBwLReJ68r7TpQxcPldNAt10OvvCy65rjJzXKRm+WiS3YkSPTI9bTbnE99DofQPafpwJeQ8yT16OlIBOnSFZ0x49vioHvvjQSDrl1bXTw0evRopk2bxtixYzn88MO5+OKLGTVqFABDhgzhwQcfZOjQoezatYvLLruMsrIyTjnlFEaMGMH48eOZPTtSVDVnzhwKCgoYMWIEw4YN409/+lOj5zzzzDN54YUXOPvss2uXXXvttdxwww2MHj2acPjbIX0nTPgeq1evrq0sruu+++fwl6eeZvSokTz33HPMmTOnRU/1DV2f1+vlySef5KyzzuKQQw7B4XBw6aWXxnzMc889l7vvvptRo0bx5ZdfRkY6jXlvAzXl4+64RqtMZ47o/Al50RFEa3pJt4eWfy3hcAjdcj1JnfQ+44ahDoc10mJCdc+bfv33HYiqEtbI/439th3Suh7VGzZs4JRTTuHTT9uiwZcSVmX1ahuGujlZrkiHLMtNdSyqGlega2wY6o75qNCE2mZz9T/MDhoEoKbHLoDsGQyisa+9PEHV9DyODAiYtCqdds3pEDp5Xe2ulYyJTbL+VjMuEGS6PVriJOA7NWDAgDbJDdQlIvTKy6LSH6LCH7SAQCQHEOmJawHAtFyHCgTxZptM+qspyhQRcrNc5HicVAfDVAfCVIdCGRMURCDL6cTjiswlYEVAJh4dJhB4vV527txJjx49LBh0UKrKzp0792jSKiK1PTFVXQTDSjCkBMNhQmElFG6+fiQd1cyV7ZDodKmOSLGY0yG4nXbjN4nVYQJB3759KSoqIpkjk5rU83q99O3bt8F1IoLbKURaDn63iERVUY2MjFgTGOrmIBoKFYnIYTT0XFJTQFezrubGL7SvehvTMXSYQOB2uxk4cGCqk2HSmIjUuSnbjdaYGpnXj8AYY8weLBAYY0yGs0BgjDEZrl32LBaR7cBXrdy9J7AjgclpLzLxujPxmiEzr9uuOTb9VfU7Uzy2y0AQDxEpaKiLdUeXidedidcMmXndds3xsaIhY4zJcBYIjDEmw2ViIHgk1QlIkUy87ky8ZsjM67ZrjkPG1REYY4zZUybmCIwxxtRhgcAYYzJcRgUCEZkoImtEZJ2IXJ/q9CSbiPQTkX+JyCoRWSkiM1OdprYiIk4RWSoib6Q6LW1FRLqKyDwR+UxEVovIEalOU7KJyFXR7/anIvK8iHib36v9EZEnRGSbiHxaZ1l3EXlbRD6P/t+ttcfPmEAgIk7gQeAHwDDgPBEZltpUJV0QuEZVhwHjgMsz4JprzARWpzoRbex+4J+qehBwKB38+kWkDzADyFfV4USGnD03talKmqeAifWWXQ8sVNVBwMLo+1bJmEAAjAXWqeqXquoHXgAmpzhNSaWqm1X14+jrMiI3hj6pTVXyiUhf4IfAY6lOS1sRkS7AMcDjAKrqV9XdKU1U23AB2SLiAnKAb1KcnqRQ1f8AxfUWTwaejr5+GjittcfPpEDQB/i6zvsiMuCmWENEBgCjgI9SnJS2cB9wLRBOcTra0kBgO/BktEjsMRHJTXWikklVNwF/ADYCm4ESVV2Q2lS1qd6qujn6egvQu7UHyqRAkLFEJA/4G3ClqpamOj3JJCKnANtUtTDVaWljLmA08LCqjgIqiKOooD2IlolPJhIE9wVyReSC1KYqNTTSD6DVfQEyKRBsAvrVed83uqxDExE3kSDwnKq+nOr0tIGjgEkisoFI8d9xIvJsapPUJoqAIlWtyfHNIxIYOrITgPWqul1VA8DLwJEpTlNb2ioi+wBE/9/W2gNlUiBYAgwSkYEi4iFSqTQ/xWlKKonMd/g4sFpVZ6c6PW1BVW9Q1b6qOoDI7/hdVe3wT4mqugX4WkSGRBcdD6xKYZLawkZgnIjkRL/rx9PBK8jrmQ9Mjb6eCrzW2gN1mKkqm6OqQRGZDrxFpHXBE6q6MsXJSrajgCnAChFZFl32a1V9M3VJMkl0BfBc9EHnS+DCFKcnqVT1IxGZB3xMpIXcUjroUBMi8jwwAegpIkXAzcAdwIsichGRYfnPbvXxbYgJY4zJbJlUNGSMMaYBFgiMMSbDWSAwxpgMZ4HAGGMynAUCY4zJcBYIjDEmw1kgMMaYDPf/KeaHYzfZz/gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ct_support_code import *\n",
    "\n",
    "#高斯核函数\n",
    "def gaussian_kernel(x1, x2, l=0.5, sigma_f=0.2):\n",
    "    m, n = x1.shape[0], x2.shape[0]\n",
    "    dist_matrix = np.zeros((m, n), dtype=float)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            dist_matrix[i][j] = np.sum((x1[i] - x2[j]) ** 2)\n",
    "    return sigma_f ** 2 * np.exp(- 0.5 / l ** 2 * dist_matrix)\n",
    "\n",
    "\n",
    "#生成观测值，取sin函数没有别的用意，单纯就是为了计算出Y\n",
    "def getY(X):\n",
    "    X = np.asarray(X)\n",
    "    Y = np.sin(X)*0.4 + np.random.normal(0, 0.05, size=X.shape)\n",
    "    return Y.tolist()\n",
    "\n",
    "#根据观察点X，修正生成高斯过程新的均值和协方差\n",
    "def update(X, X_star):\n",
    "    X = np.asarray(X)\n",
    "    X_star = np.asarray(X_star)\n",
    "    K_YY = gaussian_kernel(X, X)  # K(X,X)\n",
    "    K_ff = gaussian_kernel(X_star, X_star)  # K(X*, X*)\n",
    "    K_Yf = gaussian_kernel(X, X_star)  # K(X, X*)\n",
    "    K_fY = K_Yf.T # K(X*, X) 协方差矩阵是对称的，因此分块互为转置\n",
    "    K_YY_inv = np.linalg.inv(K_YY + 1e-8 * np.eye(len(X)))  # (N, N)\n",
    "    \n",
    "    mu_star = K_fY.dot(K_YY_inv).dot(Y)\n",
    "    cov_star = K_ff - K_fY.dot(K_YY_inv).dot(K_Yf)\n",
    "    return mu_star, cov_star\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(2, 1, sharex=True,sharey=True)\n",
    "#绘制高斯过程的先验\n",
    "X_pre = np.arange(0, 10, 0.1)\n",
    "mu_pre = np.array([0]*len(X_pre))\n",
    "Y_pre = mu_pre\n",
    "cov_pre = gaussian_kernel(X_pre, X_pre)\n",
    "uncertainty = 1.96 * np.sqrt(np.diag(cov_pre))#取95%置信区间\n",
    "ax[0].fill_between(X_pre, Y_pre + uncertainty,Y_pre - uncertainty, alpha=0.1)\n",
    "ax[0].plot(X_pre, Y_pre, label=\"expection\")\n",
    "ax[0].legend()\n",
    "\n",
    "\n",
    "#绘制基于观测值的高斯过程后验\n",
    "X = np.array([1, 3, 7, 9]).reshape(-1, 1)#4*1矩阵\n",
    "Y = getY(X)\n",
    "X_star = np.arange(0, 10, 0.1).reshape(-1, 1)\n",
    "mu_star, cov_star = update(X, X_star)\n",
    "Y_star = mu_star.ravel()\n",
    "uncertainty = 1.96 * np.sqrt(np.diag(cov_star))#取95%置信区间\n",
    "ax[1].fill_between(X_star.ravel(), Y_star + uncertainty, Y_star - uncertainty, alpha=0.1)\n",
    "ax[1].plot(X_star, Y_star, label=\"expection\")\n",
    "ax[1].scatter(X, Y, label=\"observation point\", c=\"red\", marker=\"x\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa8efa1f07d927b3f4f0623653dba6f2d02f31e75a8ec0b738cb3a1952f48903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
